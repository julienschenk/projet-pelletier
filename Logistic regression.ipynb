{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024446fc-cdd5-4e6a-a2d3-713b312a56e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813be53a-313f-4aa6-a8f3-52213b29ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Ju\\\\Downloads\\\\titanic\\\\train.csv\")\n",
    "def impute_data(df):\n",
    "  # Create imputers for different strategies\n",
    "  imputer_num = SimpleImputer(strategy=\"mean\") # Impute numerical features with mean\n",
    "  imputer_cat = SimpleImputer(strategy=\"most_frequent\") # Impute categorical features with mode\n",
    "\n",
    "  # Separate numerical and categorical columns\n",
    "  num_cols = df.select_dtypes(include=[np.number])\n",
    "  cat_cols = df.select_dtypes(include=[\"object\"])\n",
    "\n",
    "  # Impute numerical and categorical features separately\n",
    "  df[num_cols.columns] = imputer_num.fit_transform(num_cols)\n",
    "  df[cat_cols.columns] = imputer_cat.fit_transform(cat_cols)\n",
    "\n",
    "  return df\n",
    "df = impute_data(df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1665e7-f3fc-4f51-ad36-5f855302bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].fillna(df['Age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c174495a-07cf-4af8-91de-68e4e79aafe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Embarked', 'Cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4718e5-0f33-4e58-9299-300fc9dad474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important: normalement cette étape devrait être dans la partie 1\n",
    "df[\"Sex\"] = df[\"Sex\"].apply(lambda x: 0 if x == \"male\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce01869-036a-4e7b-9f3c-e0458d3de89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit les variables explicatives et les variables expliquées du modèle\n",
    "features=['Age', 'Fare','SibSp']\n",
    "X = df[features]  # On prend, de manière arbitraire, les variables 'Age', 'Fare' et 'SibSp' pour une première modélisation\n",
    "y = df['Survived']\n",
    "\n",
    "# On sépare les données, pour créer et tester le modèle (on ne peut pas faire les deux sur les mêmes données, car les estimateurs n'auraient pas de validité externe)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Spécifions le modèle\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Créons le vecteur des valeurs prédites\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculons la précision du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8d541b-3640-4fe6-a20e-257e920c2c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dans ce premier modèle, nous avons spécifié les variables explicatives de manière arbitraire.\n",
    "#Maintenant, nous allons déterminer les variables explicatives selon un critère déterminé: la corrélation avec la variable expliquée.\n",
    "#Nous allons reprendre le vecteur de corrélation vu précédement, et en extraire les variables le plus liées à la survie des passagers.\n",
    "#Au final, on intègre dans notre régression les variables à coefficient de correlation avec 'Survived' >=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bb851e-80fa-4268-a832-67ddee960a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regarder la correlation des variables avec 'Survived'\n",
    "\n",
    "numerical_features = ['Sex','Age', 'Fare', 'Parch', 'SibSp','Pclass']\n",
    "\n",
    "corr_matrices = {}\n",
    "\n",
    "# Calculons le vecteur de corrélation\n",
    "for feature in numerical_features:\n",
    "    corr_matrix = df[[feature, 'Survived']].corr(method='spearman')  # Spearman for mixed data types\n",
    "    corr_matrices[feature] = corr_matrix.iloc[1, 0]  # Extract correlation value with 'Survived'\n",
    "\n",
    "# Affichons le vecteur de corrélation\n",
    "print(\"Correlations avec 'Survived':\")\n",
    "for feature, correlation in corr_matrices.items():\n",
    "    print(f\"{feature}: {correlation:.2f}\")\n",
    "\n",
    "#NB:Y'a une erreur avec le Nan de sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c6cd00-e9fb-4438-b1dc-d51645fe07bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On extrait les variables les plus correllées\n",
    "high_corr_features = []\n",
    "for feature, correlation in corr_matrices.items():\n",
    "    if abs(correlation) > 0.3:\n",
    "        high_corr_features.append(feature)\n",
    "\n",
    "# On affiche ces variables (si des variables à rho >= 0.3 existent)\n",
    "if high_corr_features:\n",
    "    print(\"Variables à coeff. de corrélation > 0.3 (en VA):\")\n",
    "    for feature in high_corr_features:\n",
    "        print(f\"- {feature}\")\n",
    "else:\n",
    "    print(\"Il n'y a pas de variables à coeff. de corrélation > 0.3 (en VA) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0901e803-5687-405d-b401-f1f760029679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On spécifie maintenant une régression logistique avec nos nouvelles variables.\n",
    "\n",
    "#On affecte les variables à X\n",
    "X = df[high_corr_features]\n",
    "y = df['Survived']\n",
    "\n",
    "# On sépare les données, pour créer et tester le modèle (on ne peut pas faire les deux sur les mêmes données, car les estimateurs n'auraient pas de validité externe)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Spécifions le modèle\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Créons le vecteur des valeurs prédites\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculons la précision du modèle.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58960d56-e0f1-4755-a147-f8a7468a787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On observe qu'en chosissant les variables explicatives selon le critère de corrélation, on passe d'un pouvoir prédictif de 0.68 à 0.78."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6646e4f-eb11-42a2-b520-2c84a396ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maintenant, utilisons un autre critère de choix.\n",
    "#Ici, nous intégrons les variables dans le modèle selon que leur association avec la survie est statistiquement significative au seuil de 5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efa6482-7eb1-40a1-b929-ff3019b865f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important: normalement cette étape devrait être dans la partie 1\n",
    "df[\"Sex\"] = df[\"Sex\"].apply(lambda x: 0 if x == \"male\" else 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dccaaf0-a61d-4621-8233-4e08c0aead55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# On extrait les variables numériques\n",
    "numeric_cols = df.select_dtypes(include=[np.number])  \n",
    "\n",
    "# Ce vecteur vide contiendra les variables significatives après\n",
    "significant_features = []\n",
    "\n",
    "# Pour tester les différents variables on utilise une boucle\n",
    "for col in numeric_cols.columns:\n",
    "    if col != 'Survived':  # On ne teste pas la variable expliquée\n",
    "        survived_data = df[df['Survived'] == 1][col]\n",
    "        not_survived_data = df[df['Survived'] == 0][col]\n",
    "\n",
    "        # Faisons les t-test\n",
    "        t_stat, p_value = stats.ttest_ind(survived_data, not_survived_data)\n",
    "\n",
    "        # On affiche les résultats des t-test\n",
    "        print(f\"T-statistic for '{col}': {t_stat:.4f}\")   \n",
    "        print(f\"p-value for '{col}': {p_value:.4f}\")      \n",
    "        print(\"-------------------------\")\n",
    "\n",
    "        # On garde les variables selon le seuil de significativité choisi (5%)\n",
    "        if p_value < 0.05:\n",
    "            significant_features.append(col)\n",
    "\n",
    "# On affiche les variables statistiquement significatives \n",
    "print(\"Variables à p-value < 0.05:\")\n",
    "print(*significant_features, sep='\\n')  # Affichons chaque variable l'une après l'autre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2b1c54-5d05-469f-a4e3-ae856335c3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On spécifie maintenant une régression logistique avec nos nouvelles variables.\n",
    "\n",
    "#On affecte les variables significatives à X\n",
    "X = df[significant_features]\n",
    "y = df['Survived']\n",
    "\n",
    "# On sépare les données, pour créer et tester le modèle (on ne peut pas faire les deux sur les mêmes données, car les estimateurs n'auraient pas de validité externe)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Spécifions le modèle\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Créons le vecteur des valeurs prédites\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculons la précision du modèle.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a924b6e7-aea6-408c-8e8e-cf17cf5d0b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On observe que, bien qu'on retienne plus de variables que selon le critère de corrélation, le pouvoir prédictif de notre modèle baisse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
